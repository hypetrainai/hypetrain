{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython import display\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from os import listdir,mkdir,rmdir\n",
    "from os.path import join,isdir\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_net(nn.Module):\n",
    "    def __init__(self, c=3, img_size=32):\n",
    "        super(test_net, self).__init__()\n",
    "        \n",
    "        self.mp = nn.ReLU()\n",
    "        self.c1 = nn.Conv2d(3, out_channels=96,kernel_size=3,stride=1,padding=1)\n",
    "        self.b1 = nn.BatchNorm2d(96)\n",
    "        self.p1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.c2 = nn.Conv2d(96, out_channels=256,kernel_size=3,stride=1,padding=1)\n",
    "        self.b2 = nn.BatchNorm2d(256)\n",
    "        self.p2 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.c3 = nn.Conv2d(256, out_channels=512,kernel_size=3,stride=1,padding=1)\n",
    "        self.b3 = nn.BatchNorm2d(512)\n",
    "        self.c4 = nn.Conv2d(512, out_channels=512,kernel_size=3,stride=1,padding=1)\n",
    "        self.b4 = nn.BatchNorm2d(512)\n",
    "        self.c5 = nn.Conv2d(512, out_channels=384,kernel_size=3,stride=1,padding=1)\n",
    "        self.b5 = nn.BatchNorm2d(384)\n",
    "        self.p5 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.flatten_size = 384#int(384 * (float(img_size) / 2 / 2 / 2) ** 2)\n",
    "        self.a5 = nn.AvgPool2d(int(32 / 2 / 2 / 2))\n",
    "        \n",
    "        self.f6 = nn.Linear(self.flatten_size, out_features=1024)\n",
    "        self.b6 = nn.BatchNorm1d(1024)\n",
    "        self.f8 = nn.Linear(1024, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l1 = self.p1(self.mp(self.b1(self.c1(x))))\n",
    "        l2 = self.p2(self.mp(self.b2(self.c2(l1))))\n",
    "        l3 = self.mp(self.b3(self.c3(l2)))\n",
    "        l4 = self.mp(self.b4(self.c4(l3)))\n",
    "        l5 = self.p5(self.mp(self.b5(self.c5(l4))))\n",
    "        f = self.a5(l5).view(-1, self.flatten_size)\n",
    "        #f  = l5.view(-1, self.flatten_size)\n",
    "        l6 = self.mp(self.b6(self.f6(f)))\n",
    "        l8 = self.mp(self.f8(l6))\n",
    "        \n",
    "        return l1,l2,l3,l4,l5,l6,l8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_dataset(Dataset):\n",
    "    def __init__(self, filepath='/home/darvin/Data/cifar-10-train'):\n",
    "        self.datapath = filepath\n",
    "        \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for folder in listdir(self.datapath):\n",
    "            path_imgs = join(self.datapath, folder)\n",
    "            length += len(listdir(path_imgs))\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lengths = []\n",
    "        for folder in listdir(self.datapath):\n",
    "            path_imgs = join(self.datapath, folder)\n",
    "            lengths.append(len(listdir(path_imgs)))\n",
    "        for ii in range(len(lengths)):\n",
    "            if idx < lengths[ii]:\n",
    "                break\n",
    "            idx -= lengths[ii]\n",
    "        path_imgs = join(self.datapath, listdir(self.datapath)[ii])\n",
    "        path_img = join(path_imgs, listdir(path_imgs)[idx])\n",
    "        img = np.array(imageio.imread(path_img))\n",
    "        img = np.transpose(img, [2,0,1])\n",
    "        lab = ii\n",
    "        return {'img': img, 'lab': lab}\n",
    "    \n",
    "dataset = test_dataset()\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.3066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "1 tensor(2.1703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "2 tensor(2.1417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "3 tensor(2.0942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "5 tensor(1.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "6 tensor(1.7731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "7 tensor(1.8437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "8 tensor(1.8614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "9 tensor(1.8505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "10 tensor(1.7865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "11 tensor(1.7113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "12 tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "13 tensor(1.8135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "14 tensor(1.5847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "15 tensor(1.6713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "16 tensor(1.5722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "17 tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "18 tensor(1.7526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "19 tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "20 tensor(1.5277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "21 tensor(1.5486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "22 tensor(1.6458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "23 tensor(1.5184, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Process Process-4:\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-3-d8368b0d917f>\", line 16, in __getitem__\n",
      "    lengths.append(len(listdir(path_imgs)))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-5673c4537c1b>\", line 8, in <module>\n",
      "    for i_batch,sample_batch in enumerate(dataloader):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/posixpath.py\", line 421, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/posixpath.py\", line 86, in join\n",
      "    for b in map(os.fspath, p):\n",
      "  File \"/home/darvin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 28034) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "weight_decay=0.0001\n",
    "\n",
    "net = test_net().cuda()\n",
    "opt = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for i_batch,sample_batch in enumerate(dataloader):\n",
    "    opt.zero_grad()\n",
    "    data = sample_batch['img'].cuda().float()\n",
    "    labs = sample_batch['lab'].cuda().long()\n",
    "    pred = net(data)\n",
    "    L = loss(pred[-1], labs)\n",
    "    L.backward()\n",
    "    opt.step()\n",
    "    print(i_batch, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(\"def fx():\\n    print('asdf')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "fx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSANDBOX\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SANDBOX\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,pickle\n",
    "\n",
    "batchfiles = glob.glob(path_data+'/*_batch*')\n",
    "\n",
    "data_train = {}\n",
    "data_train['data'] = []\n",
    "data_train['labels'] = []\n",
    "for file in batchfiles:\n",
    "    if 'test' in file:\n",
    "        data_batch = pickle.load(open(file,'rb'), encoding='bytes')\n",
    "        data_test = {}\n",
    "        data_test['data'] = data_batch[b'data']\n",
    "        data_test['labels'] = data_batch[b'labels']\n",
    "    else:\n",
    "        data_batch = pickle.load(open(file,'rb'), encoding='bytes')\n",
    "        data_train['data'].append(data_batch[b'data'])\n",
    "        data_train['labels'].append(data_batch[b'labels'])\n",
    "data_train['data'] = np.concatenate(data_train['data'],axis=0)\n",
    "data_train['labels'] = np.concatenate(data_train['labels'],axis=0)\n",
    "\n",
    "meta_data = pickle.load(open(path_data+'/batches.meta','rb'), encoding='bytes')\n",
    "meta_data = [item.decode('utf-8') for item in meta_data[b'label_names']]\n",
    "\n",
    "data_train['data'] = np.transpose(data_train['data'].reshape([-1, 3, 32,32]), [0,2,3,1])\n",
    "data_test['data'] = np.transpose(data_test['data'].reshape([-1, 3, 32,32]), [0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = '/home/darvin/Data/cifar-10-test'\n",
    "if not isdir(path_save):\n",
    "    mkdir(path_save)\n",
    "    \n",
    "for ii in range(data_test['data'].shape[0]):\n",
    "    path_lab = join(path_save, str(data_test['labels'][ii]))\n",
    "    if not isdir(path_lab):\n",
    "        mkdir(path_lab)\n",
    "    img = data_test['data'][ii,:,:,:]\n",
    "    imageio.imwrite(join(path_lab, '{0:05d}'.format(ii)+'.png'), img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
