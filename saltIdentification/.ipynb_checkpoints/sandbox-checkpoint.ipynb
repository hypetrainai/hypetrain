{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "from os import listdir,mkdir,rmdir\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setting up code directories\n",
    "'''\n",
    "\n",
    "computer = 'Darvin'#'Kotz'\n",
    "\n",
    "if computer == 'Darvin':\n",
    "    path_data_root = '/media/darvin/data/Data/saltSegmentation'\n",
    "elif computer == 'Kotz':\n",
    "    path_data_root = '/home/kotaro/Projects/data'\n",
    "    \n",
    "path_data_tr = join(path_data_root, 'train')\n",
    "path_data_te = join(path_data_root, 'test')\n",
    "\n",
    "path_data_tr_imgs = join(path_data_tr, 'images')\n",
    "path_data_tr_masks = join(path_data_tr, 'masks')\n",
    "\n",
    "path_data_te_imgs = join(path_data_te, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading in all the images in train.\n",
    "- images: 4000 image .png's\n",
    "- masks:  4000 corresponding .png's\n",
    "\n",
    "We will also split into 9:1 training:validation\n",
    "'''\n",
    "\n",
    "X = np.zeros((4000, 1, 128, 128), dtype=np.float32)\n",
    "Y = np.zeros((4000, 1, 128, 128), dtype=np.float32)\n",
    "list_names = []\n",
    "\n",
    "for ii,name_img in enumerate(listdir(path_data_tr_imgs)):\n",
    "    img  = imageio.imread(join(path_data_tr_imgs, name_img))\n",
    "    mask = imageio.imread(join(path_data_tr_masks, name_img))\n",
    "    \n",
    "    img = np.mean(img, axis=2) / 255\n",
    "    \n",
    "    img = np.pad(img, ((13,14), (13,14)), 'constant', constant_values=0)\n",
    "    mask = np.pad(mask, ((13,14), (13,14)), 'constant', constant_values=0)\n",
    "    \n",
    "    X[ii, 0, :, :] = img.astype(np.float32)\n",
    "    Y[ii, 0, :, :] = (mask > 0).astype(np.float32)\n",
    "    list_names.append(name_img)\n",
    "\n",
    "X_tr = X[:3600, :, :, :]\n",
    "Y_tr = Y[:3600, :, :, :]\n",
    "\n",
    "X_va = X[3600:, :, :, :]\n",
    "Y_va = Y[3600:, :, :, :]\n",
    "\n",
    "X_mean = np.mean(X_tr, axis=0)\n",
    "X_tr -= X_mean\n",
    "X_va -= X_mean\n",
    "\n",
    "X_std = np.std(X_tr, axis=0)\n",
    "X_tr /= X_std + 0.0000001\n",
    "X_va /= X_std + 0.0000001\n",
    "\n",
    "print(X_tr.shape, X_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let's visualize some data.\n",
    "'''\n",
    "\n",
    "fig,ax = plt.subplots(5, 2)\n",
    "\n",
    "inds = np.random.choice(3600, 5)\n",
    "\n",
    "for ii in range(5):\n",
    "    ax[ii,0].imshow(X_tr[inds[ii], 0, :, :], cmap='bone')\n",
    "    ax[ii,0].set_title('Image')\n",
    "    ax[ii,1].imshow(Y_tr[inds[ii], 0, :, :], cmap='bone')\n",
    "    ax[ii,1].set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        self.convT1 = nn.ConvTranspose2d(480, 1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        \n",
    "        self.convT2 = nn.ConvTranspose2d(832, 1, kernel_size=8, stride=4, padding=2, bias=False)\n",
    "\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.convT3 = nn.ConvTranspose2d(1024, 1, kernel_size=16, stride=8, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pre_layers(x) #192x64x64\n",
    "        out = self.a3(out)\n",
    "        out = self.b3(out)\n",
    "        pred = self.convT1(out)\n",
    "        out = self.maxpool(out) #256x32x32\n",
    "        out = self.a4(out)\n",
    "        out = self.b4(out)\n",
    "        out = self.c4(out)\n",
    "        out = self.d4(out)\n",
    "        out = self.e4(out)\n",
    "        pred += self.convT2(out)\n",
    "        out = self.maxpool(out) #528x16x16\n",
    "        out = self.a5(out)\n",
    "        out = self.b5(out)\n",
    "        pred += self.convT3(out) #1x128x128\n",
    "        return pred\n",
    "\n",
    "class Net():\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.net = GoogLeNet().cuda()\n",
    "        self.opt = optim.Adam(self.net.parameters(), lr=lr)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def train_one_iter(self, x, y):\n",
    "        self.opt.zero_grad()\n",
    "        loss = self.compute_loss(x, y)\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, x, y):\n",
    "        pred = self.predict(x)\n",
    "        loss = -1 * torch.log(pred) * y - torch.log(1 - pred) * (1 - y)\n",
    "        return torch.mean(loss)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        out = self.net(x)\n",
    "        return self.sigm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "#print(net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "times = []\n",
    "losses_tr = []\n",
    "losses_va = []\n",
    "time_start = time.time()\n",
    "X_ba = np.zeros((batch_size, 1, 128, 128), dtype=np.float32)\n",
    "Y_ba = np.zeros((batch_size, 1, 128, 128), dtype=np.float32)\n",
    "for ii in range(1000):\n",
    "    net.net.train()\n",
    "    iters_in_epoch = int(X_tr.shape[0] / batch_size)\n",
    "    loss_tr = 0.0\n",
    "    for jj in range(iters_in_epoch):\n",
    "        inds = np.random.choice(X_tr.shape[0], batch_size)\n",
    "        for kk,ind in enumerate(inds):\n",
    "            img  = X_tr[ind, 0, :, :]\n",
    "            mask = Y_tr[ind, 0, :, :]\n",
    "            nrot = np.random.choice(4)\n",
    "            img  = np.rot90(img, nrot)\n",
    "            mask = np.rot90(mask, nrot)\n",
    "            if np.random.rand() > 0.5:\n",
    "                img = np.fliplr(img)\n",
    "                mask = np.fliplr(mask)\n",
    "            X_ba[kk, 0, :, :] = img\n",
    "            Y_ba[kk, 0, :, :] = mask\n",
    "        X_ba = X_tr[inds, :, :, :]\n",
    "        Y_ba = Y_tr[inds, :, :, :]\n",
    "        loss = net.train_one_iter(torch.from_numpy(X_ba).cuda(), torch.from_numpy(Y_ba).cuda())\n",
    "        loss_tr += loss.cpu().detach().numpy() / iters_in_epoch\n",
    "    losses_tr.append(loss_tr)\n",
    "    \n",
    "    net.net.eval()\n",
    "    iters_in_epoch = int( np.floor(X_va.shape[0] / batch_size) )\n",
    "    loss_va = 0.0\n",
    "    for kk in range(iters_in_epoch):\n",
    "        inds = np.arange(kk*batch_size, (kk+1)*batch_size)\n",
    "        X_ba = X_tr[inds, :, :, :]\n",
    "        Y_ba = Y_tr[inds, :, :, :]\n",
    "        loss = net.compute_loss(torch.from_numpy(X_ba).cuda(), torch.from_numpy(Y_ba).cuda())\n",
    "        loss_va += loss.cpu().detach().numpy() / iters_in_epoch\n",
    "    losses_va.append(loss_va)\n",
    "    \n",
    "    times.append( (time.time() - time_start) / 60 )\n",
    "    \n",
    "    plt.plot(times, losses_tr, c='b')\n",
    "    plt.plot(times, losses_va, c='r')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 259\n",
    "fig,ax = plt.subplots(1,3)\n",
    "ax[0].imshow(X_va[ind,0,:,:])\n",
    "ax[1].imshow(Y_va[ind,0,:,:])\n",
    "ax[2].imshow(net.predict(torch.from_numpy(X_va[ind,0,:,:].reshape([1,1,128,128])).cuda()).cpu().detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
